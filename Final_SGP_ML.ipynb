{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final SGP - ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinPatel04/Videobased-Dynamic-Authentication/blob/KEVIN_CNN_DLIB/Final_SGP_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlnD9l9hXrhn",
        "colab_type": "text"
      },
      "source": [
        "**Mount Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DzFrHCqXptt",
        "colab_type": "code",
        "outputId": "6841fdf9-c527-44de-b217-4dce7a3d4d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWcb3Em4XZ7-",
        "colab_type": "text"
      },
      "source": [
        "**Face Recognition on image**\n",
        "\n",
        "Face Detection (CNN)\n",
        "\n",
        "Face Recognition (DLIB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYzqrIBcXTIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.patches import Circle\n",
        "from google.colab.patches import cv2_imshow\n",
        "import dlib\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import os\n",
        "import imageio\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "\n",
        "weights = '/content/drive/My Drive/ML project/mmod_human_face_detector.dat'\n",
        "# initializing cnn face detector model\n",
        "cnn_face_detector = dlib.cnn_face_detection_model_v1(weights)\n",
        "# Get Face Detector from dlib\n",
        "# This allows us to detect faces in images\n",
        "# face_detector = dlib.get_frontal_face_detector()\n",
        "# Get Pose Predictor from dlib\n",
        "# This allows us to detect landmark points in faces and understand the pose/angle of the face\n",
        "shape_predictor = dlib.shape_predictor('/content/drive/My Drive/ML project/shape_predictor_68_face_landmarks.dat')\n",
        "# Get the face recognition model\n",
        "# This is what gives us the face encodings (numbers that identify the face of a particular person)\n",
        "face_recognition_model = dlib.face_recognition_model_v1('/content/drive/My Drive/ML project/dlib_face_recognition_resnet_model_v1.dat')\n",
        "# This is the tolerance for face comparisons\n",
        "# The lower the number - the stricter the comparison\n",
        "# To avoid false matches, use lower value\n",
        "# To avoid false negatives (i.e. faces of the same person doesn't match), use higher value\n",
        "# 0.5-0.6 works well\n",
        "TOLERANCE = 0.50\n",
        "\n",
        "def rect_to_bb(face):\n",
        "    # take a bounding predicted by dlib and convert it\n",
        "    # to the format (x, y, w, h) as we would normally do\n",
        "    # with OpenCV\n",
        "    x = face.rect.left()\n",
        "    y = face.rect.top()\n",
        "    w = face.rect.right() - x\n",
        "    h = face.rect.bottom() - y\n",
        "    return (x, y, w, h)\n",
        "\n",
        "# This function will take an image and return its face encodings using the neural network\n",
        "def get_face_encodings(path_to_image):\n",
        "    # Load image using scipy\n",
        "    # print(path_to_image)\n",
        "    image = cv2.imread(path_to_image)\n",
        "    # Detect faces using the face detector\n",
        "    # detected_faces = face_detector(image, 1)\n",
        "    res = cnn_face_detector(image,1)\n",
        "    # detected_faces.rect = detected_faces\n",
        "    shapes_faces = []\n",
        "    for r in res:\n",
        "        face = r.rect\n",
        "        # print(face)\n",
        "        # Get pose/landmarks of those faces\n",
        "        # Will be used as an input to the function that computes face encodings\n",
        "        # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n",
        "        shapes_faces.append(shape_predictor(image, face))\n",
        "    \n",
        "    # For every face detected, compute the face encodings\n",
        "    return [np.array(face_recognition_model.compute_face_descriptor(image, face_pose, 1)) for face_pose in shapes_faces]\n",
        "\n",
        "def get_vid_encodings(v_image,face):\n",
        "    # print(face)\n",
        "    # detected_faces = face_detector(v_image, 1)\n",
        "    # Get pose/landmarks of those faces\n",
        "    # Will be used as an input to the function that computes face encodings\n",
        "    # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n",
        "    shapes_faces = shape_predictor(v_image, face)\n",
        "    # For every face detected, compute the face encodings\n",
        "    # return [np.array(face_recognition_model.compute_face_descriptor(v_image, face_pose, 1)) for face_pose in shapes_faces]\n",
        "    return [np.array(face_recognition_model.compute_face_descriptor(v_image, shapes_faces, 1))]\n",
        "\n",
        "# This function takes a list of known faces\n",
        "def compare_face_encodings(known_faces, face):\n",
        "    # Finds the difference between each known face and the given face (that we are comparing)\n",
        "    # Calculate norm for the differences with each known face\n",
        "    # Return an array with True/Face values based on whether or not a known face matched with the given face\n",
        "    # A match occurs when the (norm) difference between a known face and the given face is less than or equal to the TOLERANCE value\n",
        "    return (np.linalg.norm(known_faces - face, axis=1) <= TOLERANCE)\n",
        "\n",
        "# This function returns the name of the person whose image matches with the given face (or 'Not Found')\n",
        "# known_faces is a list of face encodings\n",
        "# names is a list of the names of people (in the same order as the face encodings - to match the name with an encoding)\n",
        "# face is the face we are looking for\n",
        "def find_match(known_faces, names, face):\n",
        "    # Call compare_face_encodings to get a list of True/False values indicating whether or not there's a match\n",
        "    matches = compare_face_encodings(known_faces, face)\n",
        "    # Return the name of the first match\n",
        "    count = 0\n",
        "    for match in matches:\n",
        "        if match:\n",
        "            return names[count]\n",
        "        count += 1\n",
        "    # Return not found if no match found\n",
        "    return 'Not Found'\n",
        "\n",
        "# Get path to all the known images\n",
        "# Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg\n",
        "image_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir('/content/drive/My Drive/ML project/known faces/'))\n",
        "# Sort in alphabetical order\n",
        "image_filenames = sorted(image_filenames)\n",
        "# Get full paths to images\n",
        "paths_to_images = ['/content/drive/My Drive/ML project/known faces/' + x for x in image_filenames]\n",
        "# List of face encodings we have\n",
        "face_encodings = []\n",
        "# Loop over images to get the encoding one by one\n",
        "start = time.time()\n",
        "for path_to_image in paths_to_images:\n",
        "    # Get face encodings from the image\n",
        "    face_encodings_in_image = get_face_encodings(path_to_image)\n",
        "    # Make sure there's exactly one face in the image\n",
        "    if len(face_encodings_in_image) != 1:\n",
        "        print(\"Please change image: \" + path_to_image + \" - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n",
        "        exit()\n",
        "    # Append the face encoding found in that image to the list of face encodings we have\n",
        "    face_encodings.append(face_encodings_in_image[0])\n",
        "end = time.time()\n",
        "print(\"Execution Time for Encoding: {}\".format(end-start))\n",
        "\n",
        "# Get path to all the test images\n",
        "# Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg\n",
        "test_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir('/content/drive/My Drive/ML project/test/'))\n",
        "# Get full paths to test images\n",
        "paths_to_test_images = ['/content/drive/My Drive/ML project/test/' + x for x in test_filenames]\n",
        "# Get list of names of people by eliminating the .JPG OR .PNG extension from image filenames\n",
        "names = [x[:-4] for x in image_filenames]\n",
        "\n",
        "\n",
        "def draw_border(img, pt1, pt2, color, thickness, r, d):\n",
        "    x1,y1 = pt1\n",
        "    x2,y2 = pt2\n",
        " \n",
        "    # Top left\n",
        "    cv2.line(img, (x1 + r, y1), (x1 + r + d, y1), color, thickness)\n",
        "    cv2.line(img, (x1, y1 + r), (x1, y1 + r + d), color, thickness)\n",
        "    cv2.ellipse(img, (x1 + r, y1 + r), (r, r), 180, 0, 90, color, thickness)\n",
        " \n",
        "    # Top right\n",
        "    cv2.line(img, (x2 - r, y1), (x2 - r - d, y1), color, thickness)\n",
        "    cv2.line(img, (x2, y1 + r), (x2, y1 + r + d), color, thickness)\n",
        "    cv2.ellipse(img, (x2 - r, y1 + r), (r, r), 270, 0, 90, color, thickness)\n",
        " \n",
        "    # Bottom left\n",
        "    cv2.line(img, (x1 + r, y2), (x1 + r + d, y2), color, thickness)\n",
        "    cv2.line(img, (x1, y2 - r), (x1, y2 - r - d), color, thickness)\n",
        "    cv2.ellipse(img, (x1 + r, y2 - r), (r, r), 90, 0, 90, color, thickness)\n",
        " \n",
        "    # Bottom right\n",
        "    cv2.line(img, (x2 - r, y2), (x2 - r - d, y2), color, thickness)\n",
        "    cv2.line(img, (x2, y2 - r), (x2, y2 - r - d), color, thickness)\n",
        "    cv2.ellipse(img, (x2 - r, y2 - r), (r, r), 0, 0, 90, color, thickness)\n",
        "\n",
        "# draw each face separately\n",
        "def draw_faces_cnn(data):\n",
        "    # load the image\n",
        "    # data = pyplot.imread(filename)\n",
        "    # data = imagefile\n",
        "    # load image from file\n",
        "    # create the detector, using default weights\n",
        "    # detector = MTCNN()\n",
        "    # detect faces in the image\n",
        "    # result_list = detector.detect_faces(data)\n",
        "    # result_list = face_detector(data, 1)\n",
        "    result_list = cnn_face_detector(data, 1)\n",
        "    # print(result_list)\n",
        "    # display faces on the original image\n",
        "    # plot each face as a subplot\n",
        "    for i in range(len(result_list)):\n",
        "        # get coordinates\n",
        "        # x1, y1, width, height = result_list[i]['box']\n",
        "        x1, y1, width, height = rect_to_bb(result_list[i])\n",
        "        x2, y2 = x1 + width, y1 + height\n",
        "        draw_border(data, (x1, y1), (x2, y2), (0, 255, 0),4, 15, 10)\n",
        "        image = data[y1-40:y2+40, x1-40:x2+40]\n",
        "        res = result_list[i].rect\n",
        "        cv2_imshow(image)\n",
        "        # flag = check_faces_cnn(image,i)\n",
        "        # res = face_detector(image, 1)\n",
        "        # print(flag)\n",
        "        flag = True # if len(res)==1 else False\n",
        "        if flag==True:\n",
        "            print(\"Face Detected\")\n",
        "            # (h,w) = image.shape[:2]\n",
        "            # center = (w/2,h/2)\n",
        "            # M = cv2.getRotationMatrix2D(center,270,1.0)\n",
        "            # rotated270 = cv2.warpAffine(image,M,(h,w))\n",
        "            # face_encodings_in_image = get_vid_encodings(rotated270)\n",
        "            face_encodings_in_image = get_vid_encodings(data,res)\n",
        "            if len(face_encodings_in_image) != 1:\n",
        "                print(\"Please change image: - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n",
        "                continue\n",
        "            # Find match for the face encoding found in this test image\n",
        "            match = find_match(face_encodings, names, face_encodings_in_image[0])\n",
        "            # match = find_match(face_encodings, names, face_encodings_in_image[0])\n",
        "            # Print the path of test image and the corresponding match\n",
        "            # \" + path_to_image + \"\n",
        "            print(\"This is\",match)\n",
        "        else:\n",
        "            print(\"No Face\")\n",
        "            continue\n",
        "\n",
        "new_image_filenames = filter(lambda x: x.endswith('.jpg') or x.endswith('.png'), os.listdir('/content/drive/My Drive/ML project/test/'))\n",
        "# Sort in alphabetical order\n",
        "new_image_filenames = sorted(new_image_filenames)\n",
        "# Get full paths to images\n",
        "paths_to_new_images = ['/content/drive/My Drive/ML project/test/' + x for x in new_image_filenames]\n",
        "\"\"\"\n",
        "paths_to_new_images = [\n",
        "                       '/content/drive/My Drive/ML project/test/Frame90.jpg'\n",
        "                       ]\n",
        "\"\"\"\n",
        "start = time.time()\n",
        "for x in paths_to_new_images:\n",
        "    img = cv2.imread(x)\n",
        "    print(x)\n",
        "    #cv2_imshow(img)\n",
        "    draw_faces_cnn(img)\n",
        "end = time.time()\n",
        "print(\"Recognition time {}\".format(end - start))\n",
        "cv2.destroyAllWindows()\n",
        "print('Done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJYvzqPvYtAN",
        "colab_type": "text"
      },
      "source": [
        "**Face Recognition on video**\n",
        "\n",
        "Face Detection (CNN)\n",
        "\n",
        "Face Recognition (Dlib)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRccEQboY-To",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.patches import Circle\n",
        "from google.colab.patches import cv2_imshow\n",
        "import dlib\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import os\n",
        "import imageio\n",
        "import cv2\n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "import pytz\n",
        "\n",
        "weights = '/content/drive/My Drive/ML project/mmod_human_face_detector.dat'\n",
        "# initializing cnn face detector model\n",
        "# This allows us to detect faces in images\n",
        "cnn_face_detector = dlib.cnn_face_detection_model_v1(weights)\n",
        "# Get Pose Predictor from dlib\n",
        "# This allows us to detect landmark points in faces and understand the pose/angle of the face\n",
        "shape_predictor = dlib.shape_predictor('/content/drive/My Drive/ML project/shape_predictor_68_face_landmarks.dat')\n",
        "# Get the face recognition model\n",
        "# This is what gives us the face encodings (numbers that identify the face of a particular person)\n",
        "face_recognition_model = dlib.face_recognition_model_v1('/content/drive/My Drive/ML project/dlib_face_recognition_resnet_model_v1.dat')\n",
        "# This is the tolerance for face comparisons\n",
        "# The lower the number - the stricter the comparison\n",
        "# To avoid false matches, use lower value\n",
        "# To avoid false negatives (i.e. faces of the same person doesn't match), use higher value\n",
        "# 0.5-0.6 works well\n",
        "TOLERANCE = 0.50\n",
        "\n",
        "def rect_to_bb(face):\n",
        "    # take a bounding predicted by dlib and convert it\n",
        "    # to the format (x, y, w, h) as we would normally do\n",
        "    # with OpenCV\n",
        "    x = face.rect.left()\n",
        "    y = face.rect.top()\n",
        "    w = face.rect.right() - x\n",
        "    h = face.rect.bottom() - y\n",
        "    return (x, y, w, h)\n",
        "\n",
        "# This function will take an image and return its face encodings using the neural network\n",
        "def get_face_encodings(path_to_image):\n",
        "    # Load image\n",
        "    image = cv2.imread(path_to_image)\n",
        "    # Detect faces using the face detector\n",
        "    res = cnn_face_detector(image,1)\n",
        "    shapes_faces = []\n",
        "    for r in res:\n",
        "        face = r.rect\n",
        "        # Get pose/landmarks of those faces\n",
        "        # Will be used as an input to the function that computes face encodings\n",
        "        # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n",
        "        shapes_faces.append(shape_predictor(image, face))\n",
        "    \n",
        "    # For every face detected, compute the face encodings\n",
        "    return [np.array(face_recognition_model.compute_face_descriptor(image, face_pose, 1)) for face_pose in shapes_faces]\n",
        "\n",
        "def get_vid_encodings(v_image,face):\n",
        "    # Get pose/landmarks of those faces\n",
        "    # Will be used as an input to the function that computes face encodings\n",
        "    # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n",
        "    shapes_faces = shape_predictor(v_image, face)\n",
        "    # For every face detected, compute the face encodings\n",
        "    # return [np.array(face_recognition_model.compute_face_descriptor(v_image, face_pose, 1)) for face_pose in shapes_faces]\n",
        "    return [np.array(face_recognition_model.compute_face_descriptor(v_image, shapes_faces, 1))]\n",
        "\n",
        "# This function takes a list of known faces\n",
        "def compare_face_encodings(known_faces, face):\n",
        "    # Finds the difference between each known face and the given face (that we are comparing)\n",
        "    # Calculate norm for the differences with each known face\n",
        "    # Return an array with True/Face values based on whether or not a known face matched with the given face\n",
        "    # A match occurs when the (norm) difference between a known face and the given face is less than or equal to the TOLERANCE value\n",
        "    return (np.linalg.norm(known_faces - face, axis=1) <= TOLERANCE)\n",
        " \n",
        "def draw_border(img, pt1, pt2, color, thickness, r, d):\n",
        "    x1,y1 = pt1\n",
        "    x2,y2 = pt2\n",
        " \n",
        "    # Top left\n",
        "    img = cv2.line(img, (x1 + r, y1), (x1 + r + d, y1), color, thickness)\n",
        "    img = cv2.line(img, (x1, y1 + r), (x1, y1 + r + d), color, thickness)\n",
        "    img = cv2.ellipse(img, (x1 + r, y1 + r), (r, r), 180, 0, 90, color, thickness)\n",
        " \n",
        "    # Top right\n",
        "    img = cv2.line(img, (x2 - r, y1), (x2 - r - d, y1), color, thickness)\n",
        "    img = cv2.line(img, (x2, y1 + r), (x2, y1 + r + d), color, thickness)\n",
        "    img = cv2.ellipse(img, (x2 - r, y1 + r), (r, r), 270, 0, 90, color, thickness)\n",
        " \n",
        "    # Bottom left\n",
        "    img = cv2.line(img, (x1 + r, y2), (x1 + r + d, y2), color, thickness)\n",
        "    img = cv2.line(img, (x1, y2 - r), (x1, y2 - r - d), color, thickness)\n",
        "    img = cv2.ellipse(img, (x1 + r, y2 - r), (r, r), 90, 0, 90, color, thickness)\n",
        " \n",
        "    # Bottom right\n",
        "    img = cv2.line(img, (x2 - r, y2), (x2 - r - d, y2), color, thickness)\n",
        "    img = cv2.line(img, (x2, y2 - r), (x2, y2 - r - d), color, thickness)\n",
        "    img = cv2.ellipse(img, (x2 - r, y2 - r), (r, r), 0, 0, 90, color, thickness)\n",
        "    return img\n",
        "\n",
        "# This function returns the name of the person whose image matches with the given face (or 'Not Found')\n",
        "# known_faces is a list of face encodings\n",
        "# names is a list of the names of people (in the same order as the face encodings - to match the name with an encoding)\n",
        "# face is the face we are looking for\n",
        "def find_match(known_faces, names, face):\n",
        "    # Call compare_face_encodings to get a list of True/False values indicating whether or not there's a match\n",
        "    matches = compare_face_encodings(known_faces, face)\n",
        "    # Return the name of the first match\n",
        "    count = 0\n",
        "    for match in matches:\n",
        "        if match:\n",
        "            return names[count]\n",
        "        count += 1\n",
        "    # Return not found if no match found\n",
        "    return 'Not Found'\n",
        "\n",
        "# Get path to all the known images\n",
        "# Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg\n",
        "image_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir('/content/drive/My Drive/ML project/known faces/'))\n",
        "# Sort in alphabetical order\n",
        "image_filenames = sorted(image_filenames)\n",
        "# Get full paths to images\n",
        "paths_to_images = ['/content/drive/My Drive/ML project/known faces/' + x for x in image_filenames]\n",
        "# List of face encodings we have\n",
        "face_encodings = []\n",
        "# Loop over images to get the encoding one by one\n",
        "start = time.time()\n",
        "for path_to_image in paths_to_images:\n",
        "    # Get face encodings from the image\n",
        "    face_encodings_in_image = get_face_encodings(path_to_image)\n",
        "    # Make sure there's exactly one face in the image\n",
        "    if len(face_encodings_in_image) != 1:\n",
        "        print(\"Please change image: \" + path_to_image + \" - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n",
        "        exit()\n",
        "    # Append the face encoding found in that image to the list of face encodings we have\n",
        "    face_encodings.append(face_encodings_in_image[0])\n",
        "end = time.time()\n",
        "print(\"Execution Time for Encoding: {}\".format(end-start))\n",
        "\n",
        "# Get list of names of people by eliminating the .JPG OR .PNG extension from image filenames\n",
        "names = [x[:-4] for x in image_filenames]\n",
        "\n",
        "count = 0\n",
        "suc=True\n",
        "cap = cv2.VideoCapture('/content/drive/My Drive/ML project/test/test.mp4')\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "FPS = cap.get(cv2.CAP_PROP_FPS)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "# out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))\n",
        "# out = cv2.VideoWriter('outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
        "out = cv2.VideoWriter('outpy.avi',fourcc, 20, (frame_width,frame_height))\n",
        "\n",
        "# set time zone\n",
        "tz = pytz.timezone(\"Asia/Calcutta\")\n",
        "print(\"Video Capture Started\")\n",
        "start = time.time()\n",
        "skip = int(FPS);\n",
        "\n",
        "skip = 0;\n",
        "while suc:\n",
        "    #Read the frame\n",
        "    for t in range(skip):\n",
        "        cap.grab()\n",
        "    suc, img = cap.read()\n",
        "\n",
        "    if suc == False:\n",
        "        print('False')\n",
        "        break\n",
        "    else:\n",
        "        # rotate stream by 270 deg\n",
        "        img = np.rot90(img,3,(0,1))\n",
        "        imgframe = img.copy()\n",
        "        # detect faces in the image\n",
        "        result_list = cnn_face_detector(img, 1)\n",
        "        # display faces on the original image\n",
        "        # plot each face as a subplot\n",
        "        org = (30, 30)\n",
        "        # font \n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX \n",
        "        # fontScale \n",
        "        fontScale = 0.6\n",
        "        # Blue color in BGR \n",
        "        color = (255, 255, 255) \n",
        "        # Line thickness of 2 px \n",
        "        thickness = 1\n",
        "        \n",
        "        # get current date and time\n",
        "        now = dt.now(tz=tz) \n",
        "        # dd/mm/YY H:M:S\n",
        "        dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "        d_string = now.strftime(\"%d/%m/%Y\")\n",
        "        t_string = now.strftime(\"%H:%M:%S\")\n",
        "                    \n",
        "        framestamp = 'Frame{}'.format(count) + ' ' + dt_string\n",
        "\n",
        "        # Using cv2.putText() method \n",
        "        imgframe = cv2.putText(imgframe, framestamp, org, font,fontScale, color, thickness, cv2.LINE_AA)\n",
        "        for i in range(len(result_list)):\n",
        "            # get coordinates\n",
        "            x1, y1, width, height = rect_to_bb(result_list[i])\n",
        "            x2, y2 = x1 + width, y1 + height\n",
        "            image = img[y1-40:y2+40, x1-40:x2+40]\n",
        "            res = result_list[i].rect\n",
        "            face_encodings_in_image = get_vid_encodings(img,res)\n",
        "            if len(face_encodings_in_image) != 1:\n",
        "                print(\"Please change image: - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n",
        "                # continue\n",
        "            else:\n",
        "                # Find match for the face encoding found in this test image\n",
        "                match = find_match(face_encodings, names, face_encodings_in_image[0])\n",
        "                # match = find_match(face_encodings, names, face_encodings_in_image[0])\n",
        "                    # Print the path of test image and the corresponding match\n",
        "                    # \" + path_to_image + \"\n",
        "                # filename = \"/content/drive/My Drive/ML project/images/\" + match + \"_{}\".format(count) +\"_{}.jpg\".format(i)\n",
        "                filename = \"\" + match + \"_{}\".format(count) +\"_{}.jpg\".format(i)\n",
        "                if image.any():\n",
        "                    # font \n",
        "                    font = cv2.FONT_HERSHEY_SIMPLEX \n",
        "                    # fontScale \n",
        "                    fontScale = 0.25\n",
        "                    # Blue color in BGR \n",
        "                    color = (255, 255, 255) \n",
        "                    # Line thickness of 2 px \n",
        "                    thickness = 1\n",
        "                    # Using cv2.putText() method \n",
        "                    # image = cv2.putText(image, d_string, (5,10), font,fontScale, color, thickness, cv2.LINE_AA)\n",
        "                    # image = cv2.putText(image, t_string, (5,20), font,fontScale, color, thickness, cv2.LINE_AA)\n",
        "                    cv2.imwrite(filename,image)\n",
        "                print(\"This is\",match)\n",
        "                if match != \"Not Found\":\n",
        "                    ### Drawing Border around the detected face\n",
        "                    # color is in ( B, G, R) format\n",
        "                    imgframe = draw_border(imgframe, (x1, y1), (x2, y2), (0, 255, 0),2, 5, 5).copy()\n",
        "                    ###\n",
        "                else:\n",
        "                    ### Drawing Border around the detected face\n",
        "                    # color is in ( B, G, R) format\n",
        "                    imgframe = draw_border(imgframe, (x1, y1), (x2, y2), (0, 0, 255),2, 5, 5).copy()\n",
        "                    ###\n",
        "        cv2.imwrite(\"Frame{}.jpg\".format(count),imgframe)\n",
        "        imgframe = cv2.cvtColor(imgframe,cv2.COLOR_RGB2BGR)\n",
        "        out.write(imgframe)\n",
        "        count = count + 1\n",
        "\n",
        "end = time.time()\n",
        "print(\"Recognition time: {}\".format(end - start))\n",
        "print(\"Total Frames: \",frames)\n",
        "print(\"FPS: \",FPS)\n",
        "print(\"Skip: \",skip)\n",
        "print(\"Total Frames Processed: \",count)\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "print('Done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nifd9Ve2X600",
        "colab_type": "text"
      },
      "source": [
        "**New Registration**\n",
        "\n",
        "Face Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YI5OMp4X6ak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dlib\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import os\n",
        "import imageio\n",
        "import cv2\n",
        "import datetime as dt\n",
        "import time\n",
        "import pyrebase\n",
        "import pytz\n",
        "import firebase\n",
        "\n",
        "Config = {\n",
        "  \"apiKey\": \"AIzaSyBplgfDMaVZSDahuI2RwF24a7e2K4vVXcs\",\n",
        "  \"authDomain\": \"videobase-dynamic-auth-system.firebaseapp.com\",\n",
        "  \"databaseURL\": \"https://videobase-dynamic-auth-system.firebaseio.com\",\n",
        "  \"projectId\": \"videobase-dynamic-auth-system\",\n",
        "  \"storageBucket\": \"videobase-dynamic-auth-system.appspot.com\",\n",
        "  \"messagingSenderId\": \"542414051699\",\n",
        "  \"appId\": \"1:542414051699:web:043b564a6117971ac88d06\"\n",
        "}\n",
        "\n",
        "firebase=pyrebase.initialize_app(Config)\n",
        "storage=firebase.storage()\n",
        "\n",
        "weights = '/content/drive/My Drive/ML project/mmod_human_face_detector.dat'\n",
        "\n",
        "# Get Face Detector from dlib\n",
        "# This allows us to detect faces in images\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "# Get Pose Predictor from dlib\n",
        "# This allows us to detect landmark points in faces and understand the pose/angle of the face\n",
        "shape_predictor = dlib.shape_predictor('/content/drive/My Drive/ML project/shape_predictor_68_face_landmarks.dat')\n",
        "# Get the face recognition model\n",
        "# This is what gives us the face encodings (numbers that identify the face of a particular person)\n",
        "face_recognition_model = dlib.face_recognition_model_v1('/content/drive/My Drive/ML project/dlib_face_recognition_resnet_model_v1.dat')\n",
        "# This is the tolerance for face comparisons\n",
        "# The lower the number - the stricter the comparison\n",
        "# To avoid false matches, use lower value\n",
        "# To avoid false negatives (i.e. faces of the same person doesn't match), use higher value\n",
        "# 0.5-0.6 works well\n",
        "TOLERANCE = 0.5\n",
        "\n",
        "# This function will take an image and return its face encodings using the neural network\n",
        "def get_face_encodings(path_to_image):\n",
        "    # Load image using scipy\n",
        "    image = imageio.imread(path_to_image)\n",
        "    # Detect faces using the face detector\n",
        "    detected_faces = face_detector(image, 1)\n",
        "    # Get pose/landmarks of those faces\n",
        "    # Will be used as an input to the function that computes face encodings\n",
        "    # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n",
        "    shapes_faces = [shape_predictor(image, face) for face in detected_faces]\n",
        "    # For every face detected, compute the face encodings\n",
        "    return [np.array(face_recognition_model.compute_face_descriptor(image, face_pose, 1)) for face_pose in shapes_faces]\n",
        "\n",
        "tz = pytz.timezone('Asia/Kolkata')\n",
        "\n",
        "# Upload Function\n",
        "def upload(paths_to_images,phone_number,expdate,name,sec_code,status,designation):\n",
        "    # List of face encodings we have calulated\n",
        "    face_encodings = []\n",
        "    # List of image urls\n",
        "    urls = []\n",
        "    # Loop over images to get the encoding one by one\n",
        "    for path_to_image in paths_to_images:\n",
        "        # Get face encodings from the image\n",
        "        face_encodings_in_image = get_face_encodings(path_to_image)\n",
        "        # Make sure there's exactly one face in the image\n",
        "        if len(face_encodings_in_image) != 1:\n",
        "            print(\"Please change image: \" + path_to_image + \" - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n",
        "            exit()\n",
        "        # Append the face encoding found in that image to the list of face encodings we have\n",
        "        face_encodings.append(face_encodings_in_image[0].tolist())\n",
        "        now = dt.datetime.now(tz=tz)\n",
        "        path_to_cloud=\"Known_faces/\"+phone_number+\"_\"+str(now.timestamp())+\".jpg\"\n",
        "        #to upload the image in storage\n",
        "        public_url=storage.child(path_to_cloud).put(path_to_image)\n",
        "        public_url=storage.child(path_to_cloud).get_url(None)\n",
        "        urls.append(public_url)\n",
        "    db = firebase.database()\n",
        "    now = dt.datetime.now(tz=tz)\n",
        "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "    data_to_upload = {\n",
        "        \"name\":name,\n",
        "        \"url\": urls,\n",
        "        \"encoding\": face_encodings,\n",
        "        \"status\": status,\n",
        "        \"RegisteredBy\": sec_code,   # \"SEC001\",\n",
        "        \"RegisteredOn\": dt_string,\n",
        "        \"Contact No\": phone_number,\n",
        "        \"ExpiryDate\": expdate,\n",
        "        \"Occupation\": designation\n",
        "    }\n",
        "    add='RegisteredPerson/'+phone_number+'/'\n",
        "    db.child(add).set(data_to_upload)\n",
        "    # print(\"Uploaded\"+path_to_image)\n",
        "\n",
        "#start = time.time()\n",
        "\n",
        "\n",
        "# CALL UPLOAD() FUNTION HERE\n",
        "\n",
        "#end = time.time()\n",
        "#print(\"Time to execute: {}\",(end-start))\n",
        "print('Done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuqISo-CHC46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.patches import Circle\n",
        "from google.colab.patches import cv2_imshow\n",
        "import dlib\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import os\n",
        "import imageio\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "\n",
        "weights = '/content/drive/My Drive/ML project/mmod_human_face_detector.dat'\n",
        "# initializing cnn face detector model\n",
        "cnn_face_detector = dlib.cnn_face_detection_model_v1(weights)\n",
        "# Get Face Detector from dlib\n",
        "# This allows us to detect faces in images\n",
        "# face_detector = dlib.get_frontal_face_detector()\n",
        "# Get Pose Predictor from dlib\n",
        "# This allows us to detect landmark points in faces and understand the pose/angle of the face\n",
        "shape_predictor = dlib.shape_predictor('/content/drive/My Drive/ML project/shape_predictor_68_face_landmarks.dat')\n",
        "# Get the face recognition model\n",
        "# This is what gives us the face encodings (numbers that identify the face of a particular person)\n",
        "face_recognition_model = dlib.face_recognition_model_v1('/content/drive/My Drive/ML project/dlib_face_recognition_resnet_model_v1.dat')\n",
        "# This is the tolerance for face comparisons\n",
        "# The lower the number - the stricter the comparison\n",
        "# To avoid false matches, use lower value\n",
        "# To avoid false negatives (i.e. faces of the same person doesn't match), use higher value\n",
        "# 0.5-0.6 works well\n",
        "TOLERANCE = 0.50\n",
        "\n",
        "def rect_to_bb(face):\n",
        "    # take a bounding predicted by dlib and convert it\n",
        "    # to the format (x, y, w, h) as we would normally do\n",
        "    # with OpenCV\n",
        "    x = face.rect.left()\n",
        "    y = face.rect.top()\n",
        "    w = face.rect.right() - x\n",
        "    h = face.rect.bottom() - y\n",
        "    return (x, y, w, h)\n",
        "\n",
        "# This function will take an image and return its face encodings using the neural network\n",
        "def get_face_encodings(path_to_image):\n",
        "    # Load image using scipy\n",
        "    # print(path_to_image)\n",
        "    image = cv2.imread(path_to_image)\n",
        "    # Detect faces using the face detector\n",
        "    # detected_faces = face_detector(image, 1)\n",
        "    res = cnn_face_detector(image,1)\n",
        "    # detected_faces.rect = detected_faces\n",
        "    shapes_faces = []\n",
        "    for r in res:\n",
        "        face = r.rect\n",
        "        # print(face)\n",
        "        # Get pose/landmarks of those faces\n",
        "        # Will be used as an input to the function that computes face encodings\n",
        "        # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n",
        "        shapes_faces.append(shape_predictor(image, face))\n",
        "    \n",
        "    # For every face detected, compute the face encodings\n",
        "    return [np.array(face_recognition_model.compute_face_descriptor(image, face_pose, 1)) for face_pose in shapes_faces]\n",
        "\n",
        "def get_vid_encodings(v_image,face):\n",
        "    # print(face)\n",
        "    # detected_faces = face_detector(v_image, 1)\n",
        "    # Get pose/landmarks of those faces\n",
        "    # Will be used as an input to the function that computes face encodings\n",
        "    # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n",
        "    shapes_faces = shape_predictor(v_image, face)\n",
        "    # For every face detected, compute the face encodings\n",
        "    # return [np.array(face_recognition_model.compute_face_descriptor(v_image, face_pose, 1)) for face_pose in shapes_faces]\n",
        "    return [np.array(face_recognition_model.compute_face_descriptor(v_image, shapes_faces, 1))]\n",
        "\n",
        "# This function takes a list of known faces\n",
        "def compare_face_encodings(known_faces, face):\n",
        "    # Finds the difference between each known face and the given face (that we are comparing)\n",
        "    # Calculate norm for the differences with each known face\n",
        "    # Return an array with True/Face values based on whether or not a known face matched with the given face\n",
        "    # A match occurs when the (norm) difference between a known face and the given face is less than or equal to the TOLERANCE value\n",
        "    return (np.linalg.norm(known_faces - face, axis=1) <= TOLERANCE)\n",
        "\n",
        "# This function returns the name of the person whose image matches with the given face (or 'Not Found')\n",
        "# known_faces is a list of face encodings\n",
        "# names is a list of the names of people (in the same order as the face encodings - to match the name with an encoding)\n",
        "# face is the face we are looking for\n",
        "def find_match(known_faces, names, face):\n",
        "    # Call compare_face_encodings to get a list of True/False values indicating whether or not there's a match\n",
        "    matches = compare_face_encodings(known_faces, face)\n",
        "    # Return the name of the first match\n",
        "    count = 0\n",
        "    for match in matches:\n",
        "        if match:\n",
        "            return names[count]\n",
        "        count += 1\n",
        "    # Return not found if no match found\n",
        "    return 'Not Found'\n",
        "\n",
        "# Get path to all the known images\n",
        "# Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg\n",
        "image_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir('/content/drive/My Drive/ML project/known faces/'))\n",
        "# Sort in alphabetical order\n",
        "image_filenames = sorted(image_filenames)\n",
        "# Get full paths to images\n",
        "paths_to_images = ['/content/drive/My Drive/ML project/known faces/' + x for x in image_filenames]\n",
        "# List of face encodings we have\n",
        "face_encodings = []\n",
        "# Loop over images to get the encoding one by one\n",
        "start = time.time()\n",
        "for path_to_image in paths_to_images:\n",
        "    # Get face encodings from the image\n",
        "    face_encodings_in_image = get_face_encodings(path_to_image)\n",
        "    # Make sure there's exactly one face in the image\n",
        "    if len(face_encodings_in_image) != 1:\n",
        "        print(\"Please change image: \" + path_to_image + \" - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n",
        "        exit()\n",
        "    # Append the face encoding found in that image to the list of face encodings we have\n",
        "    face_encodings.append(face_encodings_in_image[0])\n",
        "end = time.time()\n",
        "print(\"Execution Time for Encoding: {}\".format(end-start))\n",
        "\n",
        "# Get path to all the test images\n",
        "# Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg\n",
        "test_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir('/content/drive/My Drive/ML project/test/'))\n",
        "# Get full paths to test images\n",
        "paths_to_test_images = ['/content/drive/My Drive/ML project/test/' + x for x in test_filenames]\n",
        "# Get list of names of people by eliminating the .JPG OR .PNG extension from image filenames\n",
        "names = [x[:-4] for x in image_filenames]\n",
        "\n",
        "\n",
        "def draw_border(img, pt1, pt2, color, thickness, r, d):\n",
        "    x1,y1 = pt1\n",
        "    x2,y2 = pt2\n",
        " \n",
        "    # Top left\n",
        "    cv2.line(img, (x1 + r, y1), (x1 + r + d, y1), color, thickness)\n",
        "    cv2.line(img, (x1, y1 + r), (x1, y1 + r + d), color, thickness)\n",
        "    cv2.ellipse(img, (x1 + r, y1 + r), (r, r), 180, 0, 90, color, thickness)\n",
        " \n",
        "    # Top right\n",
        "    cv2.line(img, (x2 - r, y1), (x2 - r - d, y1), color, thickness)\n",
        "    cv2.line(img, (x2, y1 + r), (x2, y1 + r + d), color, thickness)\n",
        "    cv2.ellipse(img, (x2 - r, y1 + r), (r, r), 270, 0, 90, color, thickness)\n",
        " \n",
        "    # Bottom left\n",
        "    cv2.line(img, (x1 + r, y2), (x1 + r + d, y2), color, thickness)\n",
        "    cv2.line(img, (x1, y2 - r), (x1, y2 - r - d), color, thickness)\n",
        "    cv2.ellipse(img, (x1 + r, y2 - r), (r, r), 90, 0, 90, color, thickness)\n",
        " \n",
        "    # Bottom right\n",
        "    cv2.line(img, (x2 - r, y2), (x2 - r - d, y2), color, thickness)\n",
        "    cv2.line(img, (x2, y2 - r), (x2, y2 - r - d), color, thickness)\n",
        "    cv2.ellipse(img, (x2 - r, y2 - r), (r, r), 0, 0, 90, color, thickness)\n",
        "\n",
        "# draw each face separately\n",
        "def draw_faces_cnn(data):\n",
        "    # detect faces in the image\n",
        "    result_list = cnn_face_detector(data, 1)\n",
        "    # plot each face as a subplot\n",
        "    for i in range(len(result_list)):\n",
        "        # get coordinates\n",
        "        x1, y1, width, height = rect_to_bb(result_list[i])\n",
        "        x2, y2 = x1 + width, y1 + height\n",
        "        draw_border(data, (x1, y1), (x2, y2), (0, 255, 0),4, 15, 10)\n",
        "        image = data[y1-40:y2+40, x1-40:x2+40]\n",
        "        res = result_list[i].rect\n",
        "        cv2_imshow(image)\n",
        "        flag = True\n",
        "        if flag==True:\n",
        "            print(\"Face Detected\")\n",
        "            face_encodings_in_image = get_vid_encodings(data,res)\n",
        "            if len(face_encodings_in_image) != 1:\n",
        "                print(\"Please change image: - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n",
        "                continue\n",
        "            # Find match for the face encoding found in this test image\n",
        "            match = find_match(face_encodings, names, face_encodings_in_image[0])\n",
        "            print(\"This is\",match)\n",
        "        else:\n",
        "            print(\"No Face\")\n",
        "            continue\n",
        "\n",
        "new_image_filenames = filter(lambda x: x.endswith('.jpg') or x.endswith('.png'), os.listdir('/content/drive/My Drive/ML project/test/'))\n",
        "# Sort in alphabetical order\n",
        "new_image_filenames = sorted(new_image_filenames)\n",
        "# Get full paths to images\n",
        "paths_to_new_images = ['/content/drive/My Drive/ML project/test/' + x for x in new_image_filenames]\n",
        "\"\"\"\n",
        "paths_to_new_images = [\n",
        "                       '/content/drive/My Drive/ML project/test/Frame90.jpg'\n",
        "                       ]\n",
        "\"\"\"\n",
        "start = time.time()\n",
        "for x in paths_to_new_images:\n",
        "    img = cv2.imread(x)\n",
        "    print(x)\n",
        "    #cv2_imshow(img)\n",
        "    draw_faces_cnn(img)\n",
        "end = time.time()\n",
        "print(\"Recognition time {}\".format(end - start))\n",
        "cv2.destroyAllWindows()\n",
        "print('Done')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}